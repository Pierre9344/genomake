import yaml
from pathlib import Path
from genomake.pipelines.chromake.scripts import paths as chr_paths
from genomake.pipelines.chromake.scripts import config as chr_config
import re

# check the configuration file, and modify it or raise runtime error if needed
chr_config.check_config_format(config)

onstart:
    # Create folder for the pipelines outputs
    for sequencing_name, sequencing_data in config["SEQUENCING"].items():
        sample_path = Path(sequencing_data["PATH"])
        # FOLDER CREATION
        (sample_path / "BAM").mkdir(parents=True, exist_ok=True)
        (sample_path / "BED").mkdir(parents=True, exist_ok=True)
        (sample_path / "BEDGRAPH").mkdir(parents=True, exist_ok=True)
        (sample_path / "HOMER").mkdir(parents=True, exist_ok=True)
        (sample_path / "QC/BOWTIE2").mkdir(parents=True, exist_ok=True)
        (sample_path / "QC/CUTADAPT").mkdir(parents=True, exist_ok=True)
        (sample_path / "QC/FASTQC/RAW").mkdir(parents=True, exist_ok=True)
        (sample_path / "QC/FASTQC/TRIMMED").mkdir(parents=True, exist_ok=True)
        (sample_path / "QC/flagstat").mkdir(parents=True, exist_ok=True)
        (sample_path / "QC/fragmentLen").mkdir(parents=True, exist_ok=True)
        (sample_path / "QC/MULTIQC").mkdir(parents=True, exist_ok=True)
        (sample_path / "QC/MULTIQC").mkdir(parents=True, exist_ok=True)
        (sample_path / "QC/MULTIQC").mkdir(parents=True, exist_ok=True)
        (sample_path / "TRIMMED").mkdir(parents=True, exist_ok=True)
        
        (sample_path / "QC/PICARD").mkdir(parents=True, exist_ok=True)
        
        (sample_path / "QC/stats").mkdir(parents=True, exist_ok=True)
        (sample_path / "QC/CORRELATION").mkdir(parents=True, exist_ok=True)
    

rule all:
    input:
        *chr_paths.get_all_fastq_related_paths(config, "fastqc_raw"),
        *chr_paths.get_all_fastq_related_paths(config, "multiqc_raw"),
        *chr_paths.get_all_fastq_related_paths(config, "cutadapt"),
        *chr_paths.get_all_fastq_related_paths(config, "fastqc_trimmed"),
        *chr_paths.get_all_fastq_related_paths(config, "multiqc_trimmed"),
        *chr_paths.get_all_fastq_related_paths(config, "multiqc_stats"),
        *chr_paths.get_all_fastq_related_paths(config, "bam_filtered_coord"),
        *chr_paths.get_all_fastq_related_paths(config, "bam_filtered_name"),
        *chr_paths.get_all_fastq_related_paths(config, "bedgraph"),
        *chr_paths.get_all_fastq_related_paths(config, "bed_sorted"),

def get_qos_from_time(attempt: int, default_time_min: int)->str:

    if "JOBS" not in config or "QOS_INFOS" not in config["JOBS"]:
        return "long"

    runtime_minutes = attempt * default_time_min
    suitable_qos = None

    for qos_name, qos_info in config["JOBS"]["QOS_INFOS"].items():
        maxwall = qos_info.get("MaxWall")
        if maxwall is None:
            continue
        if maxwall >= runtime_minutes:
            if suitable_qos is None or maxwall < config["JOBS"]["QOS_INFOS"][suitable_qos]["MaxWall"]:
                suitable_qos = qos_name

    # fallback to 'long' if none found
    return suitable_qos or "long"


#####################################################
# SEQUENCING QC, TRIMMING (OPTIONAL), AND ALIGNMENT #
#####################################################

for sequencing_name, sequencing_data in config["SEQUENCING"].items():
    rule:
        name:
            f"fastqc_raw_{sequencing_name}"
        input:
            *chr_paths.get_sequencing_fastq_related_paths(config, sequencing_name, "fastq_raw"),
        output:
            *chr_paths.get_sequencing_fastq_related_paths(config, sequencing_name, "fastqc_raw"),
            *chr_paths.get_sequencing_fastq_related_paths(config, sequencing_name, "multiqc_raw"),
        params:
            fastqc_outdir=str(Path(sequencing_data["PATH"]) / "QC/FASTQC/RAW/"),
            multiqc_outdir=str(Path(sequencing_data["PATH"]) / "QC/MULTIQC/"),
        threads: config["JOBS"]["CORES_PER_JOBS"]["FASTQC"]
        resources:
            mem_mb=lambda wildcards, attempt: 10000 * attempt,
            runtime=lambda wildcards, attempt: attempt * 60,
            qos=lambda wildcards, attempt: get_qos_from_time(attempt, 60),
        shell:
            r"""
            fastqc \
                {input} \
                -t {threads} \
                -o {params.fastqc_outdir}
            multiqc \
                {params.fastqc_outdir} \
                -o {params.multiqc_outdir} --force \
                -n Raw_fastq
            """
    
    if (
        "R1_ADAPTOR" in sequencing_data
        and "R2_ADAPTOR" in sequencing_data
        and sequencing_data["R1_ADAPTOR"] != ''
        and sequencing_data["R2_ADAPTOR"] != ''
    ):
        for sample_name, sample_data in sequencing_data["SAMPLES"].items():
            rule:
                name:
                    f"cutadapt_{sequencing_name}_{sample_name}"
                input:
                    str(Path(sequencing_data["PATH"]) / sample_data["R1"]),
                    str(Path(sequencing_data["PATH"]) / sample_data["R2"]),
                output:
                    str(Path(sequencing_data["PATH"]) / "TRIMMED/" / Path(sample_data["R1"]).name),
                    str(Path(sequencing_data["PATH"]) / "TRIMMED/" / Path(sample_data["R2"]).name),
                    str(Path(sequencing_data["PATH"]) / "QC/FASTQC/TRIMMED/" / re.sub(r"\.fastq(\.gz)?$", "_fastqc.html", Path(sample_data["R1"]).name)),
                    str(Path(sequencing_data["PATH"]) / "QC/FASTQC/TRIMMED/" / re.sub(r"\.fastq(\.gz)?$", "_fastqc.html", Path(sample_data["R2"]).name)),
                threads:
                    config["JOBS"]["CORES_PER_JOBS"]["CUTADAPT"]
                params:
                    r1_adaptor=sequencing_data["R1_ADAPTOR"],
                    r2_adaptor=sequencing_data["R2_ADAPTOR"],
                    cutadapt_options=sequencing_data["PARAMETERS"]["CUTADAPT"],
                    cutadapt_log=str(Path(sequencing_data["PATH"]) / "QC/CUTADAPT/" / sample_name) + ".txt",
                    fastqc_outdir=str(Path(sequencing_data["PATH"]) / "QC/FASTQC/TRIMMED/"),
                resources:
                    mem_mb=lambda wildcards, attempt: 2000 * attempt,
                    runtime=lambda wildcards, attempt: attempt * 60,
                    qos=lambda wildcards, attempt: get_qos_from_time(attempt, 60),
                shell:
                    r"""
                    cutadapt -a {params.r1_adaptor} -A {params.r2_adaptor} \
                        -o {output[0]} -p {output[1]} \
                        {params.cutadapt_options} -j {threads} \
                        {input[0]} {input[1]} > {params.cutadapt_log}
                    fastqc \
                        {output[0]} {output[1]} \
                        -t {threads} \
                        -o {params.fastqc_outdir}
                    """
            
            rule:
                name:
                    f"bowtie2_{sequencing_name}_{sample_name}"
                input:
                    str(Path(sequencing_data["PATH"]) / sample_data["R1"]),
                    str(Path(sequencing_data["PATH"]) / sample_data["R2"]),
                output:
                    str(Path(sequencing_data["PATH"]) / "QC/fragmentLen" / (sample_name + "_fragmentLen.txt")),
                    str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_chrheader.bam")),
                    str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_filtered.coordsort.bam")),
                    str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_filtered.namesort.bam")),
                    directory(str(Path(sequencing_data["PATH"]) / ("HOMER/" + sample_name))),
                    str(Path(sequencing_data["PATH"]) / ("BEDGRAPH/" + sample_name + "_UCSC_track.bedGraph")),
                    str(Path(sequencing_data["PATH"]) / ("QC/flagstat/" + sample_name + "_flagstat.txt")),
                    str(Path(sequencing_data["PATH"]) / ("QC/stats/" + sample_name + "_stats.txt")),
                threads:
                    config["JOBS"]["CORES_PER_JOBS"]["BOWTIE2"]
                params:
                    bowtie_ref=sequencing_data["PARAMETERS"]["BOWTIE2_REF"],
                    bowtie_log=str(Path(sequencing_data["PATH"]) / "QC/BOWTIE2/" / (sample_name + ".log")),
                    picard_log=str(Path(sequencing_data["PATH"]) / "QC/PICARD/" / (sample_name + "_picard.rmDup.txt")),
                    sample=sample_name,
                    sequencing=sequencing_name,
                    sam_output=str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + ".sam")),
                    filtered_sam=str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_sorted.sam")),
                    filtered2_sam=str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_rmDup.sam")),
                    bowtie_bam=str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_bowtie.bam")),
                    genome=sequencing_data["PARAMETERS"]["GENOME"],
                    homer_output=str(Path(sequencing_data["PATH"]) / ("BEDGRAPH/" + sample_name + ".bedGraph")),
                    homer_output2=str(Path(sequencing_data["PATH"]) / ("BEDGRAPH/" + sample_name + ".bedGraph.gz")),
                resources:
                    mem_mb=lambda wildcards, attempt: 60000 * attempt,
                    runtime=lambda wildcards, attempt: attempt * 180,
                    qos=lambda wildcards, attempt: get_qos_from_time(attempt, 180),
                shell:
                    r"""
                    bowtie2 -p {threads} --local --very-sensitive-local \
                        --no-mixed --no-discordant --phred33 -I 10 -X 700 \
                        -x "{params.bowtie_ref}" -1 {input[0]} -2 {input[1]} \
                        --rg-id {params.sample} --rg SM:{params.sample} \
                        --rg LB:{params.sequencing} --rg PU:{params.sample}_{params.sequencing} \
                        --rg PL:ILLUMINA -S {params.sam_output} &> {params.bowtie_log}
                    # Check fragment length of mark duplicates
                    samtools view -F 0x04 {params.sam_output} | \
                        awk -F'\t' 'function abs(x){{return ((x < 0.0) ? -x : x)}} {{print abs($9)}}' | \
                        sort | uniq -c | \
                        awk -v OFS="\t" '{{print $2, $1/2}}' > {output[0]}
                    picard SortSam -I {params.sam_output} -O {params.filtered_sam} -SORT_ORDER coordinate
                    picard MarkDuplicates -I {params.filtered_sam} -O {params.filtered2_sam} \
                         -REMOVE_DUPLICATES true \
                         -METRICS_FILE {params.picard_log}
                    # .sam to .bam
                    samtools view -@ {threads} -bS -F 0x04 {params.filtered2_sam} -o {params.bowtie_bam}
                    # add "chr" on the chromosome section and remone non-standard regions
                    samtools view -H {params.bowtie_bam} | \
                        sed -e 's/SN:\([0-9XY]\)/SN:chr\1/' -e 's/SN:MT/SN:chrM/' | \
                        samtools reheader - {params.bowtie_bam} > {output[1]}
                    samtools index {output[1]}
                    # Keep only standard chromosome
                    samtools view -b {output[1]} chr{{1..22}} chrX chrY > {output[2]}
                    samtools index {output[2]}
                    # sort by name for bamtobed conversion
                    samtools sort -n {output[2]} > {output[3]}
                    
                    # Remove TMP files
                    rm {params.sam_output} {params.filtered_sam} {params.filtered2_sam} {params.bowtie_bam}
                    
                    # HOMER track for UCSC
                    makeTagDirectory {output[4]} {output[2]} -genome {params.genome} -checkGC
                    makeUCSCfile {output[4]} -o {params.homer_output} -norm 1e7
                    gunzip {params.homer_output2}
                    awk '
                    BEGIN {{
                      for (i = 1; i <= 22; i++) chr["chr"i] = 1
                      chr["chrX"] = chr["chrY"] = 1
                    }}
                    NR == 1 {{ print; next }}
                    ($1 in chr) {{ print }}
                    ' {params.homer_output} > {output[5]}
                    
                    # samtools QC
                    samtools flagstat {output[2]} > {output[6]}
                    samtools stats {output[2]} > {output[7]}
                    """
            
            rule:
                name:
                    f"bedtools_{sequencing_name}_{sample_name}"
                input:
                    str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_filtered.namesort.bam")),
                output:
                    str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + ".bed")),
                    str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_sorted.bed")),
                    str(Path(sequencing_data["PATH"]) / "BEDGRAPH" / (sample_name + ".bw")),
                threads:
                    config["JOBS"]["CORES_PER_JOBS"]["BEDTOOLS"]
                params:
                    blacklist=config["SEQUENCING"][sequencing_name]["PARAMETERS"]["BLACKLIST_BED"],
                    chromsize=config["SEQUENCING"][sequencing_name]["PARAMETERS"]["CHROM_SIZE"],
                    bed_clean=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_clean.bed")),
                    bed_fragments=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_fragments.bed")),
                    bed_tri=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_tri.bed")),
                    bed_tri2=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_tri2.bed")),
                    bedgraph_norm=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_bowtie2.fragments.normalized.bedGraph")),
                    bedgraph_sort=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_bowtie2.fragments.sorted.bedGraph")),
                resources:
                    mem_mb=lambda wildcards, attempt: 20000 * attempt,
                    runtime=lambda wildcards, attempt: attempt * 180,
                    qos=lambda wildcards, attempt: get_qos_from_time(attempt, 180),
                shell:
                    r"""
                    bedtools bamtobed -i {input[0]} -bedpe > {output[0]}
                    awk '$1==$4 && $6-$2 < 1000 {{print $0}}' {output[0]} > {params.bed_clean}
                    cut -f 1,2,6 {params.bed_clean} | sort -k1,1 -k2,2n -k3,3n  > {params.bed_fragments}
                    egrep -v 'HG10|HG11|HG12|HG13|PATCH|HSCHR|chrKI|chrHS|chrKB|GL|chrJH|chrM|chrKL|chrAAB|chrMT|NOVEL|KZ|KK|KV|KQ|KB|JH|KI' {params.bed_fragments} > {params.bed_tri}
                    bedtools intersect -a {params.bed_tri} -b {params.blacklist} -f 0.5 -r -v > {params.bed_tri2}
                    bedtools sort -i {params.bed_tri2} > {output[1]}
                    bedtools genomecov -bg -i {output[1]} -g {params.chromsize} > {params.bedgraph_norm}
                    bedtools sort -i {params.bedgraph_norm} > {params.bedgraph_sort}
                    bedGraphToBigWig {params.bedgraph_sort} {params.chromsize} {output[2]} 
                    rm {params.bed_clean} {params.bed_fragments} {params.bed_tri} {params.bed_tri2} {params.bedgraph_norm} {params.bedgraph_sort}
                    """
                    
        if "INPUT" in sequencing_data.keys():        
            for sample_name, sample_data in sequencing_data["INPUT"].items():
                rule:
                    name:
                        f"cutadapt_{sequencing_name}_{sample_name}"
                    input:
                        str(Path(sequencing_data["PATH"]) / sample_data["R1"]),
                        str(Path(sequencing_data["PATH"]) / sample_data["R2"]),
                    output:
                        str(Path(sequencing_data["PATH"]) / "TRIMMED/" / Path(sample_data["R1"]).name),
                        str(Path(sequencing_data["PATH"]) / "TRIMMED/" / Path(sample_data["R2"]).name),
                        str(Path(sequencing_data["PATH"]) / "QC/FASTQC/TRIMMED/" / re.sub(r"\.fastq(\.gz)?$", "_fastqc.html", Path(sample_data["R1"]).name)),
                        str(Path(sequencing_data["PATH"]) / "QC/FASTQC/TRIMMED/" / re.sub(r"\.fastq(\.gz)?$", "_fastqc.html", Path(sample_data["R2"]).name)),
                    threads:
                        config["JOBS"]["CORES_PER_JOBS"]["CUTADAPT"]
                    params:
                        r1_adaptor=sequencing_data["R1_ADAPTOR"],
                        r2_adaptor=sequencing_data["R2_ADAPTOR"],
                        cutadapt_options=sequencing_data["PARAMETERS"]["CUTADAPT"],
                        cutadapt_log=str(Path(sequencing_data["PATH"]) / "QC/CUTADAPT/" / sample_name) + ".txt",
                        fastqc_outdir=str(Path(sequencing_data["PATH"]) / "QC/FASTQC/TRIMMED/"),
                    resources:
                        mem_mb=lambda wildcards, attempt: 10000 * attempt,
                        runtime=lambda wildcards, attempt: attempt * 60,
                        qos=lambda wildcards, attempt: get_qos_from_time(attempt, 60),
                    shell:
                        r"""
                        cutadapt -a {params.r1_adaptor} -A {params.r2_adaptor} \
                            -o {output[0]} -p {output[1]} \
                            {params.cutadapt_options} -j {threads} \
                            {input[0]} {input[1]} > {params.cutadapt_log}
                        fastqc \
                            {output[0]} {output[1]} \
                            -t {threads} \
                            -o {params.fastqc_outdir}
                        """
                
                rule:
                    name:
                        f"bowtie2_{sequencing_name}_{sample_name}"
                    input:
                        str(Path(sequencing_data["PATH"]) / sample_data["R1"]),
                        str(Path(sequencing_data["PATH"]) / sample_data["R2"]),
                    output:
                        str(Path(sequencing_data["PATH"]) / "QC/fragmentLen" / (sample_name + "_fragmentLen.txt")),
                        str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_chrheader.bam")),
                        str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_filtered.coordsort.bam")),
                        str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_filtered.namesort.bam")),
                        directory(str(Path(sequencing_data["PATH"]) / ("HOMER/" + sample_name))),
                        str(Path(sequencing_data["PATH"]) / ("BEDGRAPH/" + sample_name + "_UCSC_track.bedGraph")),
                        str(Path(sequencing_data["PATH"]) / ("QC/flagstat/" + sample_name + "_flagstat.txt")),
                        str(Path(sequencing_data["PATH"]) / ("QC/stats/" + sample_name + "_stats.txt")),
                    threads:
                        config["JOBS"]["CORES_PER_JOBS"]["BOWTIE2"]
                    params:
                        bowtie_ref=sequencing_data["PARAMETERS"]["BOWTIE2_REF"],
                        bowtie_log=str(Path(sequencing_data["PATH"]) / "QC/BOWTIE2/" / (sample_name + ".log")),
                        picard_log=str(Path(sequencing_data["PATH"]) / "QC/PICARD/" / (sample_name + "_picard.rmDup.txt")),
                        sample=sample_name,
                        sequencing=sequencing_name,
                        sam_output=str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + ".sam")),
                        filtered_sam=str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_sorted.sam")),
                        filtered2_sam=str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_rmDup.sam")),
                        bowtie_bam=str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_bowtie.bam")),
                        genome=sequencing_data["PARAMETERS"]["GENOME"],
                        homer_output=str(Path(sequencing_data["PATH"]) / ("BEDGRAPH/" + sample_name + ".bedGraph")),
                        homer_output2=str(Path(sequencing_data["PATH"]) / ("BEDGRAPH/" + sample_name + ".bedGraph.gz")),
                    resources:
                        mem_mb=lambda wildcards, attempt: 60000 * attempt,
                        runtime=lambda wildcards, attempt: attempt * 180,
                        qos=lambda wildcards, attempt: get_qos_from_time(attempt, 180),
                    shell:
                        r"""
                        bowtie2 -p {threads} --local --very-sensitive-local \
                            --no-mixed --no-discordant --phred33 -I 10 -X 700 \
                            -x "{params.bowtie_ref}" -1 {input[0]} -2 {input[1]} \
                            --rg-id {params.sample} --rg SM:{params.sample} \
                            --rg LB:{params.sequencing} --rg PU:{params.sample}_{params.sequencing} \
                            --rg PL:ILLUMINA -S {params.sam_output} &> {params.bowtie_log}
                        # Check fragment length of mark duplicates
                        samtools view -F 0x04 {params.sam_output} | \
                            awk -F'\t' 'function abs(x){{return ((x < 0.0) ? -x : x)}} {{print abs($9)}}' | \
                            sort | uniq -c | \
                            awk -v OFS="\t" '{{print $2, $1/2}}' > {output[0]}
                        picard SortSam -I {params.sam_output} -O {params.filtered_sam} -SORT_ORDER coordinate
                        picard MarkDuplicates -I {params.filtered_sam} -O {params.filtered2_sam} \
                             -REMOVE_DUPLICATES true \
                             -METRICS_FILE {params.picard_log}
                        # .sam to .bam
                        samtools view -@ {threads} -bS -F 0x04 {params.filtered2_sam} -o {params.bowtie_bam}
                        # add "chr" on the chromosome section and remone non-standard regions
                        samtools view -H {params.bowtie_bam} | \
                            sed -e 's/SN:\([0-9XY]\)/SN:chr\1/' -e 's/SN:MT/SN:chrM/' | \
                            samtools reheader - {params.bowtie_bam} > {output[1]}
                        samtools index {output[1]}
                        # Keep only standard chromosome
                        samtools view -b {output[1]} chr{{1..22}} chrX chrY > {output[2]}
                        samtools index {output[2]}
                        # sort by name for bamtobed conversion
                        samtools sort -n {output[2]} > {output[3]}
                        
                        # Remove TMP files
                        rm {params.sam_output} {params.filtered_sam} {params.filtered2_sam} {params.bowtie_bam}
                        
                        # HOMER track for UCSC
                        makeTagDirectory {output[4]} {output[2]} -genome {params.genome} -checkGC
                        makeUCSCfile {output[4]} -o {params.homer_output} -norm 1e7
                        gunzip {params.homer_output2}
                        awk '
                        BEGIN {{
                          for (i = 1; i <= 22; i++) chr["chr"i] = 1
                          chr["chrX"] = chr["chrY"] = 1
                        }}
                        NR == 1 {{ print; next }}
                        ($1 in chr) {{ print }}
                        ' {params.homer_output} > {output[5]}
                        
                        # samtools QC
                        samtools flagstat {output[2]} > {output[6]}
                        samtools stats {output[2]} > {output[7]}
                        """
                
                rule:
                    name:
                        f"bedtools_{sequencing_name}_{sample_name}"
                    input:
                        str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_filtered.namesort.bam")),
                    output:
                        str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + ".bed")),
                        str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_sorted.bed")),
                        str(Path(sequencing_data["PATH"]) / "BEDGRAPH" / (sample_name + ".bw")),
                    threads:
                        config["JOBS"]["CORES_PER_JOBS"]["BEDTOOLS"]
                    params:
                        blacklist=config["SEQUENCING"][sequencing_name]["PARAMETERS"]["BLACKLIST_BED"],
                        chromsize=config["SEQUENCING"][sequencing_name]["PARAMETERS"]["CHROM_SIZE"],
                        bed_clean=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_clean.bed")),
                        bed_fragments=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_fragments.bed")),
                        bed_tri=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_tri.bed")),
                        bed_tri2=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_tri2.bed")),
                        bedgraph_norm=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_bowtie2.fragments.normalized.bedGraph")),
                        bedgraph_sort=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_bowtie2.fragments.sorted.bedGraph")),
                    resources:
                        mem_mb=lambda wildcards, attempt: 20000 * attempt,
                        runtime=lambda wildcards, attempt: attempt * 180,
                        qos=lambda wildcards, attempt: get_qos_from_time(attempt, 180),
                    shell:
                        r"""
                        bedtools bamtobed -i {input[0]} -bedpe > {output[0]}
                        awk '$1==$4 && $6-$2 < 1000 {{print $0}}' {output[0]} > {params.bed_clean}
                        cut -f 1,2,6 {params.bed_clean} | sort -k1,1 -k2,2n -k3,3n  > {params.bed_fragments}
                        egrep -v 'HG10|HG11|HG12|HG13|PATCH|HSCHR|chrKI|chrHS|chrKB|GL|chrJH|chrM|chrKL|chrAAB|chrMT|NOVEL|KZ|KK|KV|KQ|KB|JH|KI' {params.bed_fragments} > {params.bed_tri}
                        bedtools intersect -a {params.bed_tri} -b {params.blacklist} -f 0.5 -r -v > {params.bed_tri2}
                        bedtools sort -i {params.bed_tri2} > {output[1]}
                        bedtools genomecov -bg -i {output[1]} -g {params.chromsize} > {params.bedgraph_norm}
                        bedtools sort -i {params.bedgraph_norm} > {params.bedgraph_sort}
                        bedGraphToBigWig {params.bedgraph_sort} {params.chromsize} {output[2]} 
                        rm {params.bed_clean} {params.bed_fragments} {params.bed_tri} {params.bed_tri2} {params.bedgraph_norm} {params.bedgraph_sort}
                        """
        
        # multiqc of all trimmed fastq
        rule:
            name:
                f"multiqc_trimmed_{sequencing_name}"
            input:
                *chr_paths.get_sequencing_fastq_related_paths(config, sequencing_name, "fastqc_trimmed"),
                *chr_paths.get_sequencing_fastq_related_paths(config, sequencing_name, "flagstat"),
            output:
                chr_paths.get_sequencing_fastq_related_paths(config, sequencing_name, "multiqc_trimmed"),
                chr_paths.get_sequencing_fastq_related_paths(config, sequencing_name, "multiqc_stats"),
            threads:
                1,
            params:
                fastqc_outdir=str(Path(sequencing_data["PATH"]) / "QC/FASTQC/TRIMMED/"),
                multiqc_outdir=str(Path(sequencing_data["PATH"]) / "QC/MULTIQC/"),
                flagstat=str(Path(sequencing_data["PATH"]) / "QC/flagstat/"),
                stats=str(Path(sequencing_data["PATH"]) / "QC/stats/"),
            resources:
                mem_mb=lambda wildcards, attempt: 10000 * attempt,
                runtime=lambda wildcards, attempt: attempt * 60,
                qos=lambda wildcards, attempt: get_qos_from_time(attempt, 60),
            shell:
                r"""
                multiqc {params.fastqc_outdir} -o {params.multiqc_outdir} --force -n Trimmed_fastq
                multiqc {params.flagstat} {params.stats} -d -o {params.multiqc_outdir} --force -n Bam_report
                """
                  
    else:
        # If there no adaptor for trimming we use BWA on the original fastq (samples and input) do add later (same rules but not trimming)
        for sample_name, sample_data in sequencing_data["SAMPLES"].items():
            rule:
                name:
                    f"bowtie2_{sequencing_name}_{sample_name}"
                input:
                    str(Path(sequencing_data["PATH"]) / sample_data["R1"]),
                    str(Path(sequencing_data["PATH"]) / sample_data["R2"]),
                output:
                    str(Path(sequencing_data["PATH"]) / "QC/fragmentLen" / (sample_name + "_fragmentLen.txt")),
                    str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_chrheader.bam")),
                    str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_filtered.coordsort.bam")),
                    str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_filtered.namesort.bam")),
                    directory(str(Path(sequencing_data["PATH"]) / ("HOMER/" + sample_name))),
                    str(Path(sequencing_data["PATH"]) / ("BEDGRAPH/" + sample_name + "_UCSC_track.bedGraph")),
                    str(Path(sequencing_data["PATH"]) / ("QC/flagstat/" + sample_name + "_flagstat.txt")),
                    str(Path(sequencing_data["PATH"]) / ("QC/stats/" + sample_name + "_stats.txt")),
                threads:
                    config["JOBS"]["CORES_PER_JOBS"]["BOWTIE2"]
                params:
                    bowtie_ref=sequencing_data["PARAMETERS"]["BOWTIE2_REF"],
                    bowtie_log=str(Path(sequencing_data["PATH"]) / "QC/BOWTIE2/" / (sample_name + ".log")),
                    picard_log=str(Path(sequencing_data["PATH"]) / "QC/PICARD/" / (sample_name + "_picard.rmDup.txt")),
                    sample=sample_name,
                    sequencing=sequencing_name,
                    sam_output=str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + ".sam")),
                    filtered_sam=str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_sorted.sam")),
                    filtered2_sam=str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_rmDup.sam")),
                    bowtie_bam=str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_bowtie.bam")),
                    genome=sequencing_data["PARAMETERS"]["GENOME"],
                    homer_output=str(Path(sequencing_data["PATH"]) / ("BEDGRAPH/" + sample_name + ".bedGraph")),
                    homer_output2=str(Path(sequencing_data["PATH"]) / ("BEDGRAPH/" + sample_name + ".bedGraph.gz")),
                resources:
                    mem_mb=lambda wildcards, attempt: 60000 * attempt,
                    runtime=lambda wildcards, attempt: attempt * 180,
                    qos=lambda wildcards, attempt: get_qos_from_time(attempt, 180),
                shell:
                    r"""
                    bowtie2 -p {threads} --local --very-sensitive-local \
                        --no-mixed --no-discordant --phred33 -I 10 -X 700 \
                        -x "{params.bowtie_ref}" -1 {input[0]} -2 {input[1]} \
                        --rg-id {params.sample} --rg SM:{params.sample} \
                        --rg LB:{params.sequencing} --rg PU:{params.sample}_{params.sequencing} \
                        --rg PL:ILLUMINA -S {params.sam_output} &> {params.bowtie_log}
                    # Check fragment length of mark duplicates
                    samtools view -F 0x04 {params.sam_output} | \
                        awk -F'\t' 'function abs(x){{return ((x < 0.0) ? -x : x)}} {{print abs($9)}}' | \
                        sort | uniq -c | \
                        awk -v OFS="\t" '{{print $2, $1/2}}' > {output[0]}
                    picard SortSam -I {params.sam_output} -O {params.filtered_sam} -SORT_ORDER coordinate
                    picard MarkDuplicates -I {params.filtered_sam} -O {params.filtered2_sam} \
                         -REMOVE_DUPLICATES true \
                         -METRICS_FILE {params.picard_log}
                    # .sam to .bam
                    samtools view -@ {threads} -bS -F 0x04 {params.filtered2_sam} -o {params.bowtie_bam}
                    # add "chr" on the chromosome section and remone non-standard regions
                    samtools view -H {params.bowtie_bam} | \
                        sed -e 's/SN:\([0-9XY]\)/SN:chr\1/' -e 's/SN:MT/SN:chrM/' | \
                        samtools reheader - {params.bowtie_bam} > {output[1]}
                    samtools index {output[1]}
                    # Keep only standard chromosome
                    samtools view -b {output[1]} chr{{1..22}} chrX chrY > {output[2]}
                    samtools index {output[2]}
                    # sort by name for bamtobed conversion
                    samtools sort -n {output[2]} > {output[3]}
                    
                    # Remove TMP files
                    rm {params.sam_output} {params.filtered_sam} {params.filtered2_sam} {params.bowtie_bam}
                    
                    # HOMER track for UCSC
                    makeTagDirectory {output[4]} {output[2]} -genome {params.genome} -checkGC
                    makeUCSCfile {output[4]} -o {params.homer_output} -norm 1e7
                    gunzip {params.homer_output2}
                    awk '
                    BEGIN {{
                      for (i = 1; i <= 22; i++) chr["chr"i] = 1
                      chr["chrX"] = chr["chrY"] = 1
                    }}
                    NR == 1 {{ print; next }}
                    ($1 in chr) {{ print }}
                    ' {params.homer_output} > {output[5]}
                    
                    # samtools QC
                    samtools flagstat {output[2]} > {output[6]}
                    samtools stats {output[2]} > {output[7]}
                    """
            
            rule:
                name:
                    f"bedtools_{sequencing_name}_{sample_name}"
                input:
                    str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_filtered.namesort.bam")),
                output:
                    str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + ".bed")),
                    str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_sorted.bed")),
                    str(Path(sequencing_data["PATH"]) / "BEDGRAPH" / (sample_name + ".bw")),
                threads:
                    config["JOBS"]["CORES_PER_JOBS"]["BEDTOOLS"]
                params:
                    blacklist=config["SEQUENCING"][sequencing_name]["PARAMETERS"]["BLACKLIST_BED"],
                    chromsize=config["SEQUENCING"][sequencing_name]["PARAMETERS"]["CHROM_SIZE"],
                    bed_clean=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_clean.bed")),
                    bed_fragments=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_fragments.bed")),
                    bed_tri=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_tri.bed")),
                    bed_tri2=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_tri2.bed")),
                    bedgraph_norm=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_bowtie2.fragments.normalized.bedGraph")),
                    bedgraph_sort=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_bowtie2.fragments.sorted.bedGraph")),
                resources:
                    mem_mb=lambda wildcards, attempt: 20000 * attempt,
                    runtime=lambda wildcards, attempt: attempt * 180,
                    qos=lambda wildcards, attempt: get_qos_from_time(attempt, 180),
                shell:
                    r"""
                    bedtools bamtobed -i {input[0]} -bedpe > {output[0]}
                    awk '$1==$4 && $6-$2 < 1000 {{print $0}}' {output[0]} > {params.bed_clean}
                    cut -f 1,2,6 {params.bed_clean} | sort -k1,1 -k2,2n -k3,3n  > {params.bed_fragments}
                    egrep -v 'HG10|HG11|HG12|HG13|PATCH|HSCHR|chrKI|chrHS|chrKB|GL|chrJH|chrM|chrKL|chrAAB|chrMT|NOVEL|KZ|KK|KV|KQ|KB|JH|KI' {params.bed_fragments} > {params.bed_tri}
                    bedtools intersect -a {params.bed_tri} -b {params.blacklist} -f 0.5 -r -v > {params.bed_tri2}
                    bedtools sort -i {params.bed_tri2} > {output[1]}
                    bedtools genomecov -bg -i {output[1]} -g {params.chromsize} > {params.bedgraph_norm}
                    bedtools sort -i {params.bedgraph_norm} > {params.bedgraph_sort}
                    bedGraphToBigWig {params.bedgraph_sort} {params.chromsize} {output[2]} 
                    rm {params.bed_clean} {params.bed_fragments} {params.bed_tri} {params.bed_tri2} {params.bedgraph_norm} {params.bedgraph_sort}
                    """
        
        if "INPUT" in sequencing_data.keys():        
            for sample_name, sample_data in sequencing_data["INPUT"].items():
                rule:
                    name:
                        f"bowtie2_{sequencing_name}_{sample_name}"
                    input:
                        str(Path(sequencing_data["PATH"]) / sample_data["R1"]),
                        str(Path(sequencing_data["PATH"]) / sample_data["R2"]),
                    output:
                        str(Path(sequencing_data["PATH"]) / "QC/fragmentLen" / (sample_name + "_fragmentLen.txt")),
                        str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_chrheader.bam")),
                        str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_filtered.coordsort.bam")),
                        str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_filtered.namesort.bam")),
                        directory(str(Path(sequencing_data["PATH"]) / ("HOMER/" + sample_name))),
                        str(Path(sequencing_data["PATH"]) / ("BEDGRAPH/" + sample_name + "_UCSC_track.bedGraph")),
                        str(Path(sequencing_data["PATH"]) / ("QC/flagstat/" + sample_name + "_flagstat.txt")),
                        str(Path(sequencing_data["PATH"]) / ("QC/stats/" + sample_name + "_stats.txt")),
                    threads:
                        config["JOBS"]["CORES_PER_JOBS"]["BOWTIE2"]
                    params:
                        bowtie_ref=sequencing_data["PARAMETERS"]["BOWTIE2_REF"],
                        bowtie_log=str(Path(sequencing_data["PATH"]) / "QC/BOWTIE2/" / (sample_name + ".log")),
                        picard_log=str(Path(sequencing_data["PATH"]) / "QC/PICARD/" / (sample_name + "_picard.rmDup.txt")),
                        sample=sample_name,
                        sequencing=sequencing_name,
                        sam_output=str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + ".sam")),
                        filtered_sam=str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_sorted.sam")),
                        filtered2_sam=str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_rmDup.sam")),
                        bowtie_bam=str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_bowtie.bam")),
                        genome=sequencing_data["PARAMETERS"]["GENOME"],
                        homer_output=str(Path(sequencing_data["PATH"]) / ("BEDGRAPH/" + sample_name + ".bedGraph")),
                        homer_output2=str(Path(sequencing_data["PATH"]) / ("BEDGRAPH/" + sample_name + ".bedGraph.gz")),
                    resources:
                        mem_mb=lambda wildcards, attempt: 60000 * attempt,
                        runtime=lambda wildcards, attempt: attempt * 180,
                        qos=lambda wildcards, attempt: get_qos_from_time(attempt, 180),
                    shell:
                        r"""
                        bowtie2 -p {threads} --local --very-sensitive-local \
                            --no-mixed --no-discordant --phred33 -I 10 -X 700 \
                            -x "{params.bowtie_ref}" -1 {input[0]} -2 {input[1]} \
                            --rg-id {params.sample} --rg SM:{params.sample} \
                            --rg LB:{params.sequencing} --rg PU:{params.sample}_{params.sequencing} \
                            --rg PL:ILLUMINA -S {params.sam_output} &> {params.bowtie_log}
                        # Check fragment length of mark duplicates
                        samtools view -F 0x04 {params.sam_output} | \
                            awk -F'\t' 'function abs(x){{return ((x < 0.0) ? -x : x)}} {{print abs($9)}}' | \
                            sort | uniq -c | \
                            awk -v OFS="\t" '{{print $2, $1/2}}' > {output[0]}
                        picard SortSam -I {params.sam_output} -O {params.filtered_sam} -SORT_ORDER coordinate
                        picard MarkDuplicates -I {params.filtered_sam} -O {params.filtered2_sam} \
                             -REMOVE_DUPLICATES true \
                             -METRICS_FILE {params.picard_log}
                        # .sam to .bam
                        samtools view -@ {threads} -bS -F 0x04 {params.filtered2_sam} -o {params.bowtie_bam}
                        # add "chr" on the chromosome section and remone non-standard regions
                        samtools view -H {params.bowtie_bam} | \
                            sed -e 's/SN:\([0-9XY]\)/SN:chr\1/' -e 's/SN:MT/SN:chrM/' | \
                            samtools reheader - {params.bowtie_bam} > {output[1]}
                        samtools index {output[1]}
                        # Keep only standard chromosome
                        samtools view -b {output[1]} chr{{1..22}} chrX chrY > {output[2]}
                        samtools index {output[2]}
                        # sort by name for bamtobed conversion
                        samtools sort -n {output[2]} > {output[3]}
                        
                        # Remove TMP files
                        rm {params.sam_output} {params.filtered_sam} {params.filtered2_sam} {params.bowtie_bam}
                        
                        # HOMER track for UCSC
                        makeTagDirectory {output[4]} {output[2]} -genome {params.genome} -checkGC
                        makeUCSCfile {output[4]} -o {params.homer_output} -norm 1e7
                        gunzip {params.homer_output2}
                        awk '
                        BEGIN {{
                          for (i = 1; i <= 22; i++) chr["chr"i] = 1
                          chr["chrX"] = chr["chrY"] = 1
                        }}
                        NR == 1 {{ print; next }}
                        ($1 in chr) {{ print }}
                        ' {params.homer_output} > {output[5]}
                        
                        # samtools QC
                        samtools flagstat {output[2]} > {output[6]}
                        samtools stats {output[2]} > {output[7]}
                        """
                
                rule:
                    name:
                        f"bedtools_{sequencing_name}_{sample_name}"
                    input:
                        str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_filtered.namesort.bam")),
                    output:
                        str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + ".bed")),
                        str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_sorted.bed")),
                        str(Path(sequencing_data["PATH"]) / "BEDGRAPH" / (sample_name + ".bw")),
                    threads:
                        config["JOBS"]["CORES_PER_JOBS"]["BEDTOOLS"]
                    params:
                        blacklist=config["SEQUENCING"][sequencing_name]["PARAMETERS"]["BLACKLIST_BED"],
                        chromsize=config["SEQUENCING"][sequencing_name]["PARAMETERS"]["CHROM_SIZE"],
                        bed_clean=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_clean.bed")),
                        bed_fragments=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_fragments.bed")),
                        bed_tri=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_tri.bed")),
                        bed_tri2=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_tri2.bed")),
                        bedgraph_norm=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_bowtie2.fragments.normalized.bedGraph")),
                        bedgraph_sort=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_bowtie2.fragments.sorted.bedGraph")),
                    resources:
                        mem_mb=lambda wildcards, attempt: 20000 * attempt,
                        runtime=lambda wildcards, attempt: attempt * 180,
                        qos=lambda wildcards, attempt: get_qos_from_time(attempt, 180),
                    shell:
                        r"""
                        bedtools bamtobed -i {input[0]} -bedpe > {output[0]}
                        awk '$1==$4 && $6-$2 < 1000 {{print $0}}' {output[0]} > {params.bed_clean}
                        cut -f 1,2,6 {params.bed_clean} | sort -k1,1 -k2,2n -k3,3n  > {params.bed_fragments}
                        egrep -v 'HG10|HG11|HG12|HG13|PATCH|HSCHR|chrKI|chrHS|chrKB|GL|chrJH|chrM|chrKL|chrAAB|chrMT|NOVEL|KZ|KK|KV|KQ|KB|JH|KI' {params.bed_fragments} > {params.bed_tri}
                        bedtools intersect -a {params.bed_tri} -b {params.blacklist} -f 0.5 -r -v > {params.bed_tri2}
                        bedtools sort -i {params.bed_tri2} > {output[1]}
                        bedtools genomecov -bg -i {output[1]} -g {params.chromsize} > {params.bedgraph_norm}
                        bedtools sort -i {params.bedgraph_norm} > {params.bedgraph_sort}
                        bedGraphToBigWig {params.bedgraph_sort} {params.chromsize} {output[2]} 
                        rm {params.bed_clean} {params.bed_fragments} {params.bed_tri} {params.bed_tri2} {params.bedgraph_norm} {params.bedgraph_sort}
                        """
        
        rule:
            name:
                f"multiqc_trimmed_{sequencing_name}"
            input:
                *chr_paths.get_sequencing_fastq_related_paths(config, sequencing_name, "flagstat"),
                *chr_paths.get_sequencing_fastq_related_paths(config, sequencing_name, "stats"),
            output:
                chr_paths.get_sequencing_fastq_related_paths(config, sequencing_name, "multiqc_stats"),
            threads:
                1,
            params:
                flagstat=str(Path(sequencing_data["PATH"]) / "QC/flagstat/"),
                stats=str(Path(sequencing_data["PATH"]) / "QC/stats/"),
                multiqc_outdir=str(Path(sequencing_data["PATH"]) / "QC/MULTIQC"),
            resources:
                mem_mb=lambda wildcards, attempt: 10000 * attempt,
                runtime=lambda wildcards, attempt: attempt * 60,
                qos=lambda wildcards, attempt: get_qos_from_time(attempt, 60),
            shell:
                r"""
                multiqc {params.flagstat} {params.stats} -d -o {params.multiqc_outdir} --force -n Bam_report
                """
                
    # RULES for after the alignment
    
    # Bam summary
    rule:
        name:
            f"multibamsummary_{sequencing_name}"
        input:
            *chr_paths.get_sequencing_fastq_related_paths(config, sequencing_name, "bam_filtered_coord"),
        output:
            str(Path(sequencing_data["PATH"]) / "QC/CORRELATION" / (sequencing_name + "correlation_matrix.npz")),
            str(Path(sequencing_data["PATH"]) / "QC/CORRELATION" / (sequencing_name + "correlation_plot.png")),
        threads:
            config["JOBS"]["CORES_PER_JOBS"]["MULTIBAMSUMMARY"],
        params:
            labels=lambda wildcards, input: " ".join(Path(b).name.replace("_filtered.coordsort.bam", "") for b in input)
        resources:
            mem_mb=lambda wildcards, attempt: 10000 * attempt,
            runtime=lambda wildcards, attempt: attempt * 60,
            qos=lambda wildcards, attempt: get_qos_from_time(attempt, 60),
        shell:
            r"""                
            multiBamSummary bins -p {threads} --verbose \
                --bamfiles {input} --labels {params.labels} -o {output[0]}
            
            plotCorrelation -in {output[0]} -c spearman -p heatmap \
                --colorMap RdYlBu -o {output[1]}
            """

#####################
# PROJECTS ANALYSES #
#####################

# Peak Calling

    
    
    
    
    