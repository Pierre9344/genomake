import yaml
from pathlib import Path
from genomake.pipelines.chromake.scripts import paths as chr_paths
import re

onstart:
    if "SEQUENCING" not in config:
        raise RuntimeError("The configuration file is missing the 'SEQUENCING' field!")
    if "PROJECTS" not in config:
        raise RuntimeError("The configuration file is missing the 'PROJECTS' field!")
    if "JOBS" not in config:
        print("Jobs field missing from the configuration file. Adding one with the example default value")
        config["JOBS"] = {
              "CORES_PER_JOBS": {
              "FASTQC": 10,
              "CUTADAPT": 10,
              "BOWTIE2": 30
              },
              "QOS_INFOS": {
                  "short": {"MaxWall": 2000},
                  "medium": {"MaxWall": 5000},
                  "long": {"MaxWall": 15000}
               }
        }
    else:
        if "CORES_PER_JOBS" not in config["JOBS"]:
            print("Number of cores to use for the jobs is not indicated in the config file. Using the pipeline default values")
            config["JOBS"]["CORES_PER_JOBS"] = {
                "FASTQC": 10,
                "CUTADAPT": 10,
                "BOWTIE2": 30,
                "SAMTOOLS_QC": 5,
                "MULTIBAMSUMMARY": 5,
                "BEDTOOLS": 5
            }
        else:
            if "FASTQC" not in config["JOBS"]["CORES_PER_JOBS"]:
                print("Number of cores not indicated for fastqc, defaulting to 10")
                config["JOBS"]["CORES_PER_JOBS"]["FASTQC"] = 10
            if "CUTADAPT" not in config["JOBS"]["CORES_PER_JOBS"]:
                print("Number of cores not indicated for cutadapt, defaulting to 10")
                config["JOBS"]["CORES_PER_JOBS"]["CUTADAPT"] = 10
            if "BOWTIE2" not in config["JOBS"]["CORES_PER_JOBS"]:
                print("Number of cores not indicated for bowtie2, defaulting to 30")
                config["JOBS"]["CORES_PER_JOBS"]["BOWTIE2"] = 30
            if "SAMTOOLS_QC" not in config["JOBS"]["CORES_PER_JOBS"]:
                print("Number of cores not indicated for samtools QC, defaulting to 5")
                config["JOBS"]["CORES_PER_JOBS"]["SAMTOOLS_QC"] = 5
            if "MULTIBAMSUMMARY" not in config["JOBS"]["CORES_PER_JOBS"]:
                print("Number of cores not indicated for deeptools multiBamSummary rule defaulting to 5")
                config["JOBS"]["CORES_PER_JOBS"]["MULTIBAMSUMMARY"] = 5
                if "BEDTOOLS" not in config["JOBS"]["CORES_PER_JOBS"]:
                    print("Number of cores not indicated for bedtools rule defaulting to 5")
                    config["JOBS"]["CORES_PER_JOBS"]["BEDTOOLS"] = 5
        if "QOS_INFOS" not in config["JOBS"]:
            print("The 'QOS_INFOS' field is missing in the config file. Using the example default values to be abble to set the ressources field of the rules. Will be ignored if executor is not set.")
            config["JOBS"]["QOS_INFOS"] = {
                "short": {"MaxWall": 2000},
                "medium": {"MaxWall": 5000},
                "long": {"MaxWall": 15000}
            }
        
    for sequencing_name, sequencing_data in config["SEQUENCING"].items():
        if "INPUT" in sequencing_data and len(sequencing_data["INPUT"]) >= 2:
            first_input = list(sequencing_data["INPUT"].keys())[0]
            print(
                f"The {sequencing_name} sequencing list more than one input. ",
                f"All of them will be sequencded but only the first one '{first_input}' ",
                "will be used for the samples peak calling."
            )
        
        # PARAMETERS CHECK
        if "PARAMETERS" not in sequencing_data:
            raise RuntimeError("Each sequencing must have a parameters field to indicates at least the genome reference for bowtie2, and the genome used (hg38, mm10, ...)!")
        else:
            # CUTADAPT is optional
            if "CUTADAPT" not in config["SEQUENCING"][sequencing_name]["PARAMETERS"]:
                print(f"The {sequencing_name} seqencing don't list parameters for cutadapt. Using the pipeline default: '-q 20 --pair-filter=any'.")
                config["SEQUENCING"][sequencing_name]["PARAMETERS"]["CUTADAPT"] = ""
            
            # Parameters representing path are not optional
            parameters_error="""Each sequencing must have a parameters field to indicates at least:
              - the genome reference for bowtie2 (BOWTIE2_REF)
              - a bed of blacklisted regions (BLACKLIST_BED)
              - a file indicating the chromosome size (CHROM_SIZE), see https://hgdownload.cse.ucsc.edu/goldenpath/hg38/bigZips/ for the format.
              - the genome used, either the .fa file of the reference used to build bowtie2 reference (toplevel.fa for ensembl) or a string such as hg38 or mm10 if the genome was configured in homer with configureHomer.pl (GENOME)
            """
            if "BOWTIE2_REF" not in config["SEQUENCING"][sequencing_name]["PARAMETERS"]:
                raise RuntimeError(parameters_error)
            if "GENOME" not in config["SEQUENCING"][sequencing_name]["PARAMETERS"]:
                raise RuntimeError(parameters_error)
            if "BLACKLIST_BED" not in config["SEQUENCING"][sequencing_name]["PARAMETERS"]:
                raise RuntimeError(parameters_error)
            if "CHROM_SIZE" not in config["SEQUENCING"][sequencing_name]["PARAMETERS"]:
                raise RuntimeError(
                raise RuntimeError(parameters_error)
            del parameters_error
        sample_path = Path(sequencing_data["PATH"])
        
        # FOLDER CREATION
        if not sample_path.exists():
            raise RuntimeError(f"The sequencing {str(sequencing_name)} PATH field is not valid. Please check your config file!")
        (sample_path / "QC/FASTQC/RAW").mkdir(parents=True, exist_ok=True)
        (sample_path / "QC/FASTQC/TRIMMED").mkdir(parents=True, exist_ok=True)
        (sample_path / "QC/MULTIQC/RAW").mkdir(parents=True, exist_ok=True)
        (sample_path / "QC/MULTIQC/TRIMMED").mkdir(parents=True, exist_ok=True)
        (sample_path / "QC/MULTIQC/STATS").mkdir(parents=True, exist_ok=True)
        (sample_path / "QC/CUTADAPT").mkdir(parents=True, exist_ok=True)
        (sample_path / "QC/BOWTIE2").mkdir(parents=True, exist_ok=True)
        (sample_path / "QC/PICARD").mkdir(parents=True, exist_ok=True)
        (sample_path / "QC/flagstat").mkdir(parents=True, exist_ok=True)
        (sample_path / "QC/fragmentLen").mkdir(parents=True, exist_ok=True)
        (sample_path / "QC/stats").mkdir(parents=True, exist_ok=True)
        (sample_path / "QC/CORRELATION/").mkdir(parents=True, exist_ok=True)
        (sample_path / "TRIMMED").mkdir(parents=True, exist_ok=True)
        (sample_path / "BAM").mkdir(parents=True, exist_ok=True)
        (sample_path / "HOMER/").mkdir(parents=True, exist_ok=True)
        (sample_path / "BED").mkdir(parents=True, exist_ok=True)
        (sample_path / "BEDGRAPH").mkdir(parents=True, exist_ok=True)
    
    # PROJECT CHECK
    for project_name, project_data in config["PROJECTS"].items():
        if "PROJECT_PATH" not in project_data:
            raise RuntimeError(f"The project {project_name} is missing the 'PROJECT_PATH field! Please add a valid path.")
        elif project_data["PROJECT_PATH"] == "":
            raise RuntimeError(f"The project {project_name} 'PROJECT_PATH field is empty! Please add a valid path.")
        else:
            Path(project_data["PROJECT_PATH"]).mkdir(parents=True, exist_ok=True)


rule all:
    input:
        *chr_paths.get_all_fastq_related_paths(config, "fastqc_raw"),
        *chr_paths.get_all_fastq_related_paths(config, "multiqc_raw"),
        *chr_paths.get_all_fastq_related_paths(config, "cutadapt"),
        *chr_paths.get_all_fastq_related_paths(config, "fastqc_trimmed"),
        *chr_paths.get_all_fastq_related_paths(config, "multiqc_trimmed"),
        *chr_paths.get_all_fastq_related_paths(config, "bam_filtered"),
        *chr_paths.get_all_fastq_related_paths(config, "bedgraph"),

def get_qos_from_time(attempt: int, default_time_min: int)->str:

    if "JOBS" not in config or "QOS_INFOS" not in config["JOBS"]:
        return "long"

    runtime_minutes = attempt * default_time_min
    suitable_qos = None

    for qos_name, qos_info in config["JOBS"]["QOS_INFOS"].items():
        maxwall = qos_info.get("MaxWall")
        if maxwall is None:
            continue
        if maxwall >= runtime_minutes:
            if suitable_qos is None or maxwall < config["JOBS"]["QOS_INFOS"][suitable_qos]["MaxWall"]:
                suitable_qos = qos_name

    # fallback to 'long' if none found
    return suitable_qos or "long"


for sequencing_name, sequencing_data in config["SEQUENCING"].items():
    rule:
        name:
            f"fastqc_raw_{sequencing_name}"
        input:
            *chr_paths.get_sequencing_fastq_related_paths(config, sequencing_name, "fastq_raw"),
        output:
            *chr_paths.get_sequencing_fastq_related_paths(config, sequencing_name, "fastqc_raw"),
            *chr_paths.get_sequencing_fastq_related_paths(config, sequencing_name, "multiqc_raw"),
        params:
            fastqc_outdir=str(Path(sequencing_data["PATH"]) / "QC/FASTQC/RAW/"),
            multiqc_outdir=str(Path(sequencing_data["PATH"]) / "QC/MULTIQC/RAW/"),
        threads: config["JOBS"]["CORES_PER_JOBS"]["FASTQC"]
        resources:
            mem_mb=lambda wildcards, attempt: 10000 * attempt,
            runtime=lambda wildcards, attempt: attempt * 60,
            qos=lambda wildcards, attempt: get_qos_from_time(attempt, 60),
        shell:
            r"""
            fastqc \
                {input} \
                -t {threads} \
                -o {params.fastqc_outdir}
            multiqc \
                {params.fastqc_outdir} \
                -o {params.multiqc_outdir} --force
            """
    
    
    if (
        "R1_ADAPTOR" in sequencing_data
        and "R2_ADAPTOR" in sequencing_data
        and sequencing_data["R1_ADAPTOR"] != ''
        and sequencing_data["R2_ADAPTOR"] != ''
    ):
        for sample_name, sample_data in sequencing_data["SAMPLES"].items():
            rule:
                name:
                    f"cutadapt_{sequencing_name}_{sample_name}"
                input:
                    str(Path(sequencing_data["PATH"]) / sample_data["R1"]),
                    str(Path(sequencing_data["PATH"]) / sample_data["R2"]),
                output:
                    str(Path(sequencing_data["PATH"]) / "TRIMMED/" / Path(sample_data["R1"]).name),
                    str(Path(sequencing_data["PATH"]) / "TRIMMED/" / Path(sample_data["R2"]).name),
                    str(Path(sequencing_data["PATH"]) / "QC/FASTQC/TRIMMED/" / re.sub(r"\.fastq(\.gz)?$", "_fastqc.html", Path(sample_data["R1"]).name)),
                    str(Path(sequencing_data["PATH"]) / "QC/FASTQC/TRIMMED/" / re.sub(r"\.fastq(\.gz)?$", "_fastqc.html", Path(sample_data["R2"]).name)),
                threads:
                    config["JOBS"]["CORES_PER_JOBS"]["CUTADAPT"]
                params:
                    r1_adaptor=sequencing_data["R1_ADAPTOR"],
                    r2_adaptor=sequencing_data["R2_ADAPTOR"],
                    cutadapt_options=sequencing_data["PARAMETERS"]["CUTADAPT"],
                    cutadapt_log=str(Path(sequencing_data["PATH"]) / "QC/CUTADAPT/" / sample_name) + ".txt",
                    fastqc_outdir=str(Path(sequencing_data["PATH"]) / "QC/FASTQC/TRIMMED/"),
                resources:
                    mem_mb=lambda wildcards, attempt: 2000 * attempt,
                    runtime=lambda wildcards, attempt: attempt * 60,
                    qos=lambda wildcards, attempt: get_qos_from_time(attempt, 60),
                shell:
                    r"""
                    cutadapt -a {params.r1_adaptor} -A {params.r2_adaptor} \
                        -o {output[0]} -p {output[1]} \
                        {params.cutadapt_options} -j {threads} \
                        {input[0]} {input[1]} > {params.cutadapt_log}
                    fastqc \
                        {output[0]} {output[1]} \
                        -t {threads} \
                        -o {params.fastqc_outdir}
                    """
            
            rule:
                name:
                    f"bowtie2_{sequencing_name}_{sample_name}"
                input:
                    str(Path(sequencing_data["PATH"]) / "TRIMMED/" / Path(sample_data["R1"]).name),
                    str(Path(sequencing_data["PATH"]) / "TRIMMED/" / Path(sample_data["R2"]).name),
                output:
                    str(Path(sequencing_data["PATH"]) / "QC/fragmentLen" / (sample_name + "_fragmentLen.txt")),
                    str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_chrheader.bam")),
                    str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_filtered.bam")),
                    directory(str(Path(sequencing_data["PATH"]) / ("HOMER/" + sample_name))),
                    str(Path(sequencing_data["PATH"]) / ("BEDGRAPH/" + sample_name + "_UCSC_track.bedGraph")),
                    str(Path(sequencing_data["PATH"]) / ("QC/flagstat/" + sample_name + "_flagstat.txt")),
                    str(Path(sequencing_data["PATH"]) / ("QC/stats/" + sample_name + "_stats.txt")),
                threads:
                    config["JOBS"]["CORES_PER_JOBS"]["BOWTIE2"]
                params:
                    bowtie_ref=sequencing_data["PARAMETERS"]["BOWTIE2_REF"],
                    bowtie_log=str(Path(sequencing_data["PATH"]) / "QC/BOWTIE2/" / (sample_name + ".log")),
                    picard_log=str(Path(sequencing_data["PATH"]) / "QC/PICARD/" / (sample_name + "_picard.rmDup.txt")),
                    sample=sample_name,
                    sequencing=sequencing_name,
                    sam_output=str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + ".sam")),
                    filtered_sam=str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_sorted.sam")),
                    filtered2_sam=str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_rmDup.sam")),
                    bowtie_bam=str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_bowtie.bam")),
                    genome=sequencing_data["PARAMETERS"]["GENOME"],
                    homer_output=str(Path(sequencing_data["PATH"]) / ("BEDGRAPH/" + sample_name + ".bedGraph")),
                    homer_output2=str(Path(sequencing_data["PATH"]) / ("BEDGRAPH/" + sample_name + ".bedGraph.gz")),
                resources:
                    mem_mb=lambda wildcards, attempt: 60000 * attempt,
                    runtime=lambda wildcards, attempt: attempt * 180,
                    qos=lambda wildcards, attempt: get_qos_from_time(attempt, 180),
                shell:
                    r"""
                    bowtie2 -p {threads} --local --very-sensitive-local \
                        --no-mixed --no-discordant --phred33 -I 10 -X 700 \
                        -x "{params.bowtie_ref}" -1 {input[0]} -2 {input[1]} \
                        --rg-id {params.sample} --rg SM:{params.sample} \
                        --rg LB:{params.sequencing} --rg PU:{params.sample}_{params.sequencing} \
                        --rg PL:ILLUMINA -S {params.sam_output} &> {params.bowtie_log}
                    # Check fragment length of mark duplicates
                    samtools view -F 0x04 {params.sam_output} | \
                        awk -F'\t' 'function abs(x){{return ((x < 0.0) ? -x : x)}} {{print abs($9)}}' | \
                        sort | uniq -c | \
                        awk -v OFS="\t" '{{print $2, $1/2}}' > {output[0]}
                    picard SortSam -I {params.sam_output} -O {params.filtered_sam} -SORT_ORDER coordinate
                    picard MarkDuplicates -I {params.filtered_sam} -O {params.filtered2_sam} \
                         -REMOVE_DUPLICATES true \
                         -METRICS_FILE {params.picard_log}
                    # .sam to .bam
                    samtools view -@ {threads} -bS -F 0x04 {params.filtered2_sam} -o {params.bowtie_bam}
                    # add "chr" on the chromosome section and remone non-standard regions
                    samtools view -H {params.bowtie_bam} | \
                        sed -e 's/SN:\([0-9XY]\)/SN:chr\1/' -e 's/SN:MT/SN:chrM/' | \
                        samtools reheader - {params.bowtie_bam} > {output[1]}
                    samtools index {output[1]}
                    samtools view -b {output[1]} chr{{1..22}} chrX chrY > {output[2]}
                    samtools index {output[2]}
                    rm {params.sam_output} {params.filtered_sam} {params.filtered2_sam} {params.bowtie_bam}
                    
                    # HOMER track for UCSC
                    makeTagDirectory {output[3]} {output[2]} -genome {params.genome} -checkGC
                    makeUCSCfile {output[3]} -o {params.homer_output} -norm 1e7
                    gunzip {params.homer_output2}
                    awk '
                    BEGIN {{
                      for (i = 1; i <= 22; i++) chr["chr"i] = 1
                      chr["chrX"] = chr["chrY"] = 1
                    }}
                    NR == 1 {{ print; next }}
                    ($1 in chr) {{ print }}
                    ' {params.homer_output} > {output[4]}
                    
                    # samtools QC
                    samtools flagstat {output[2]} > {output[5]}
                    samtools stats {output[2]} > {output[6]}
                    """
            
            rule:
                name:
                    f"bedtools_{sequencing_name}_{sample_name}"
                input:
                    str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_filtered.bam")),
                output:
                    str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + ".bed")),
                    str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_sorted.bed")),
                    str(Path(sequencing_data["PATH"]) / "BEDGRAPH" / (sample_name + ".bw")),
                threads:
                    config["JOBS"]["CORES_PER_JOBS"]["BEDTOOLS"]
                params:
                    blacklist=config["SEQUENCING"][sequencing_name]["PARAMETERS"]["BLACKLIST_BED"],
                    chromsize=config["SEQUENCING"][sequencing_name]["PARAMETERS"]["CHROM_SIZE"]
                    bed_clean=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_clean.bed")),
                    bed_fragments=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_fragments.bed")),
                    bed_tri=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_tri.bed")),
                    bed_tri2=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_tri2.bed")),
                    bedgraph_norm=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_bowtie2.fragments.normalized.bedGraph")),
                    bedgraph_sort=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_bowtie2.fragments.normalized.bedGraph")),
                resources:
                    mem_mb=lambda wildcards, attempt: 20000 * attempt,
                    runtime=lambda wildcards, attempt: attempt * 180,
                    qos=lambda wildcards, attempt: get_qos_from_time(attempt, 180),
                shell:
                    r"""
                    bedtools bamtobed -i {intput[0]} -bedpe > {output[0]}
                    awk '$1==$4 && $6-$2 < 1000 {{print $0}}' {output[0]} > {params.bed_clean}
                    cut -f 1,2,6 {params.bed_clean} | sort -k1,1 -k2,2n -k3,3n  > {params.bed_fragments}
                    egrep -v 'HG10|HG11|HG12|HG13|PATCH|HSCHR|chrKI|chrHS|chrKB|GL|chrJH|chrM|chrKL|chrAAB|chrMT|NOVEL|KZ|KK|KV|KQ|KB|JH|KI' {params.bed_fragments} > {params.bed_tri}
                    bedtools intersect -a {params.bed_tri} -b {params.blacklist} -f 0.5 -r -v > {params.bed_tri2}
                    bedtools sort -i {params.bed_tri2} > {output[1]}
                    bedtools genomecov -bg -i {output[1]} -g {params.chromsize} > {params.bedgraph_norm}
                    bedtools sort -i {params.bedgrapg_norm} > {params.bedgrapg_sorm}
                    bedGraphToBigWig {params.bedgraph_sorm} {params.chromsize} {output[2]} 
                    rm {params.bed_clean} {params.bed_fragments} {params.bed_tri} {params.bed_tri2} {params.bedgraph_norm} {params.bedgraph_sort}
                    """
                    
        if "INPUT" in sequencing_data.keys():        
            for sample_name, sample_data in sequencing_data["INPUT"].items():
                rule:
                    name:
                        f"cutadapt_{sequencing_name}_{sample_name}"
                    input:
                        str(Path(sequencing_data["PATH"]) / sample_data["R1"]),
                        str(Path(sequencing_data["PATH"]) / sample_data["R2"]),
                    output:
                        str(Path(sequencing_data["PATH"]) / "TRIMMED/" / Path(sample_data["R1"]).name),
                        str(Path(sequencing_data["PATH"]) / "TRIMMED/" / Path(sample_data["R2"]).name),
                        str(Path(sequencing_data["PATH"]) / "QC/FASTQC/TRIMMED/" / re.sub(r"\.fastq(\.gz)?$", "_fastqc.html", Path(sample_data["R1"]).name)),
                        str(Path(sequencing_data["PATH"]) / "QC/FASTQC/TRIMMED/" / re.sub(r"\.fastq(\.gz)?$", "_fastqc.html", Path(sample_data["R2"]).name)),
                    threads:
                        config["JOBS"]["CORES_PER_JOBS"]["CUTADAPT"]
                    params:
                        r1_adaptor=sequencing_data["R1_ADAPTOR"],
                        r2_adaptor=sequencing_data["R2_ADAPTOR"],
                        cutadapt_options=sequencing_data["PARAMETERS"]["CUTADAPT"],
                        cutadapt_log=str(Path(sequencing_data["PATH"]) / "QC/CUTADAPT/" / sample_name) + ".txt",
                        fastqc_outdir=str(Path(sequencing_data["PATH"]) / "QC/FASTQC/TRIMMED/"),
                    resources:
                        mem_mb=lambda wildcards, attempt: 10000 * attempt,
                        runtime=lambda wildcards, attempt: attempt * 60,
                        qos=lambda wildcards, attempt: get_qos_from_time(attempt, 60),
                    shell:
                        r"""
                        cutadapt -a {params.r1_adaptor} -A {params.r2_adaptor} \
                            -o {output[0]} -p {output[1]} \
                            {params.cutadapt_options} -j {threads} \
                            {input[0]} {input[1]} > {params.cutadapt_log}
                        fastqc \
                            {output[0]} {output[1]} \
                            -t {threads} \
                            -o {params.fastqc_outdir}
                        """
                
                rule:
                    name:
                        f"bowtie2_{sequencing_name}_{sample_name}"
                    input:
                        str(Path(sequencing_data["PATH"]) / "TRIMMED/" / Path(sample_data["R1"]).name),
                        str(Path(sequencing_data["PATH"]) / "TRIMMED/" / Path(sample_data["R2"]).name),
                    output:
                        str(Path(sequencing_data["PATH"]) / "QC/fragmentLen" / (sample_name + "_fragmentLen.txt")),
                        str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_chrheader.bam")),
                        str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_filtered.bam")),
                        directory(str(Path(sequencing_data["PATH"]) / ("HOMER/" + sample_name))),
                        str(Path(sequencing_data["PATH"]) / ("BEDGRAPH/" + sample_name + "_UCSC_track.bedGraph")),
                        str(Path(sequencing_data["PATH"]) / ("QC/flagstat/" + sample_name + "_flagstat.txt")),
                        str(Path(sequencing_data["PATH"]) / ("QC/stats/" + sample_name + "_stats.txt")),
                    threads:
                        config["JOBS"]["CORES_PER_JOBS"]["BOWTIE2"]
                    params:
                        bowtie_ref=sequencing_data["PARAMETERS"]["BOWTIE2_REF"],
                        bowtie_log=str(Path(sequencing_data["PATH"]) / "QC/BOWTIE2/" / (sample_name + ".log")),
                        picard_log=str(Path(sequencing_data["PATH"]) / "QC/PICARD/" / (sample_name + "_picard.rmDup.txt")),
                        sample=sample_name,
                        sequencing=sequencing_name,
                        sam_output=str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + ".sam")),
                        filtered_sam=str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_sorted.sam")),
                        filtered2_sam=str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_rmDup.sam")),
                        bowtie_bam=str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_bowtie.bam")),
                        genome=sequencing_data["PARAMETERS"]["GENOME"],
                        homer_output=str(Path(sequencing_data["PATH"]) / ("BEDGRAPH/" + sample_name + ".bedGraph")),
                        homer_output2=str(Path(sequencing_data["PATH"]) / ("BEDGRAPH/" + sample_name + ".bedGraph.gz")),
                    resources:
                        mem_mb=lambda wildcards, attempt: 60000 * attempt,
                        runtime=lambda wildcards, attempt: attempt * 180,
                        qos=lambda wildcards, attempt: get_qos_from_time(attempt, 180),
                    shell:
                        r"""
                        bowtie2 -p {threads} --local --very-sensitive-local \
                            --no-mixed --no-discordant --phred33 -I 10 -X 700 \
                            -x "{params.bowtie_ref}" -1 {input[0]} -2 {input[1]} \
                            --rg-id {params.sample} --rg SM:{params.sample} \
                            --rg LB:{params.sequencing} --rg PU:{params.sample}_{params.sequencing} \
                            --rg PL:ILLUMINA -S {params.sam_output} &> {params.bowtie_log}
                        # Check fragment length of mark duplicates
                        samtools view -F 0x04 {params.sam_output} | \
                            awk -F'\t' 'function abs(x){{return ((x < 0.0) ? -x : x)}} {{print abs($9)}}' | \
                            sort | uniq -c | \
                            awk -v OFS="\t" '{{print $2, $1/2}}' > {output[0]}
                        picard SortSam -I {params.sam_output} -O {params.filtered_sam} -SORT_ORDER coordinate
                        picard MarkDuplicates -I {params.filtered_sam} -O {params.filtered2_sam} \
                             -REMOVE_DUPLICATES true \
                             -METRICS_FILE {params.picard_log}
                        # .sam to .bam
                        samtools view -@ {threads} -bS -F 0x04 {params.filtered2_sam} -o {params.bowtie_bam}
                        # add "chr" on the chromosome section and remone non-standard regions
                        samtools view -H {params.bowtie_bam} | \
                            sed -e 's/SN:\([0-9XY]\)/SN:chr\1/' -e 's/SN:MT/SN:chrM/' | \
                            samtools reheader - {params.bowtie_bam} > {output[1]}
                        samtools index {output[1]}
                        samtools view -b {output[1]} chr{{1..22}} chrX chrY > {output[2]}
                        samtools index {output[2]}
                        rm {params.sam_output} {params.filtered_sam} {params.filtered2_sam} {params.bowtie_bam}
                        
                        # HOMER track for UCSC
                        makeTagDirectory {output[3]} {output[2]} -genome {params.genome} -checkGC
                        makeUCSCfile {output[3]} -o {params.homer_output} -norm 1e7
                        gunzip {params.homer_output2}
                        awk '
                        BEGIN {{
                          for (i = 1; i <= 22; i++) chr["chr"i] = 1
                          chr["chrX"] = chr["chrY"] = 1
                        }}
                        NR == 1 {{ print; next }}
                        ($1 in chr) {{ print }}
                        ' {params.homer_output} > {output[4]}
                        
                        # samtools QC
                        samtools flagstat {output[2]} > {output[5]}
                        samtools stats {output[2]} > {output[6]}
                        """
                rule:
                    name:
                        f"bedtools_{sequencing_name}_{sample_name}"
                    input:
                        str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_filtered.bam")),
                    output:
                        str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + ".bed")),
                        str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_sorted.bed")),
                        str(Path(sequencing_data["PATH"]) / "BEDGRAPH" / (sample_name + ".bw")),
                    threads:
                        config["JOBS"]["CORES_PER_JOBS"]["BEDTOOLS"]
                    params:
                        blacklist=config["SEQUENCING"][sequencing_name]["PARAMETERS"]["BLACKLIST_BED"],
                        chromsize=config["SEQUENCING"][sequencing_name]["PARAMETERS"]["CHROM_SIZE"]
                        bed_clean=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_clean.bed")),
                        bed_fragments=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_fragments.bed")),
                        bed_tri=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_tri.bed")),
                        bed_tri2=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_tri2.bed")),
                        bedgraph_norm=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_bowtie2.fragments.normalized.bedGraph")),
                        bedgraph_sort=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_bowtie2.fragments.normalized.bedGraph")),
                    resources:
                        mem_mb=lambda wildcards, attempt: 20000 * attempt,
                        runtime=lambda wildcards, attempt: attempt * 180,
                        qos=lambda wildcards, attempt: get_qos_from_time(attempt, 180),
                    shell:
                        r"""
                        bedtools bamtobed -i {intput[0]} -bedpe > {output[0]}
                        awk '$1==$4 && $6-$2 < 1000 {{print $0}}' {output[0]} > {params.bed_clean}
                        cut -f 1,2,6 {params.bed_clean} | sort -k1,1 -k2,2n -k3,3n  > {params.bed_fragments}
                        egrep -v 'HG10|HG11|HG12|HG13|PATCH|HSCHR|chrKI|chrHS|chrKB|GL|chrJH|chrM|chrKL|chrAAB|chrMT|NOVEL|KZ|KK|KV|KQ|KB|JH|KI' {params.bed_fragments} > {params.bed_tri}
                        bedtools intersect -a {params.bed_tri} -b {params.blacklist} -f 0.5 -r -v > {params.bed_tri2}
                        bedtools sort -i {params.bed_tri2} > {output[1]}
                        bedtools genomecov -bg -i {output[1]} -g {params.chromsize} > {params.bedgraph_norm}
                        bedtools sort -i {params.bedgrapg_norm} > {params.bedgrapg_sorm}
                        bedGraphToBigWig {params.bedgraph_sorm} {params.chromsize} {output[2]} 
                        rm {params.bed_clean} {params.bed_fragments} {params.bed_tri} {params.bed_tri2} {params.bedgraph_norm} {params.bedgraph_sort}
                        """
        
        # multiqc of all trimmed fastq
        rule:
            name:
                f"multiqc_trimmed_{sequencing_name}"
            input:
                *chr_paths.get_sequencing_fastq_related_paths(config, sequencing_name, "fastqc_trimmed"),
                *chr_paths.get_sequencing_fastq_related_paths(config, sequencing_name, "stats"),
            output:
                *chr_paths.get_sequencing_fastq_related_paths(config, sequencing_name, "multiqc_trimmed"),
                *chr_paths.get_sequencing_fastq_related_paths(config, sequencing_name, "multiqc_stats"),
            threads:
                1,
            params:
                fastqc_outdir=str(Path(sequencing_data["PATH"]) / "QC/FASTQC/TRIMMED/"),
                multiqc_outdir=str(Path(sequencing_data["PATH"]) / "QC/MULTIQC/TRIMMED/"),
                fastqc_outdir=str(Path(sequencing_data["PATH"]) / "QC/stats/"),
                multiqc_outdir=str(Path(sequencing_data["PATH"]) / "QC/MULTIQC/STATS/"),
            resources:
                mem_mb=lambda wildcards, attempt: 10000 * attempt,
                runtime=lambda wildcards, attempt: attempt * 60,
                qos=lambda wildcards, attempt: get_qos_from_time(attempt, 60),
            shell:
                r"""
                multiqc {params.fastqc_outdir} -o {params.multiqc_outdir} --force
                multiqc {params.multiqc_outdir2} -o {params.fastqc_outdir2} --force
                """
                  
    else:
        # If there no adaptor for trimming we use BWA on the original fastq (samples and input) do add later (same rules but not trimming)
        for sample_name, sample_data in sequencing_data["SAMPLES"].items():
            rule:
                name:
                    f"bowtie2_{sequencing_name}_{sample_name}"
                input:
                    str(Path(sequencing_data["PATH"]) / sample_data["R1"]),
                    str(Path(sequencing_data["PATH"]) / sample_data["R2"]),
                output:
                    str(Path(sequencing_data["PATH"]) / "QC/fragmentLen" / (sample_name + "_fragmentLen.txt")),
                    str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_chrheader.bam")),
                    str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_filtered.bam")),
                    directory(str(Path(sequencing_data["PATH"]) / ("HOMER/" + sample_name))),
                    str(Path(sequencing_data["PATH"]) / ("BEDGRAPH/" + sample_name + "_UCSC_track.bedGraph")),
                    str(Path(sequencing_data["PATH"]) / ("QC/flagstat/" + sample_name + "_flagstat.txt")),
                    str(Path(sequencing_data["PATH"]) / ("QC/stats/" + sample_name + "_stats.txt")),
                threads:
                    config["JOBS"]["CORES_PER_JOBS"]["BOWTIE2"]
                params:
                    bowtie_ref=sequencing_data["PARAMETERS"]["BOWTIE2_REF"],
                    bowtie_log=str(Path(sequencing_data["PATH"]) / "QC/BOWTIE2/" / (sample_name + ".log")),
                    picard_log=str(Path(sequencing_data["PATH"]) / "QC/PICARD/" / (sample_name + "_picard.rmDup.txt")),
                    sample=sample_name,
                    sequencing=sequencing_name,
                    sam_output=str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + ".sam")),
                    filtered_sam=str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_sorted.sam")),
                    filtered2_sam=str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_rmDup.sam")),
                    bowtie_bam=str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_bowtie.bam")),
                    genome=sequencing_data["PARAMETERS"]["GENOME"],
                    homer_output=str(Path(sequencing_data["PATH"]) / ("BEDGRAPH/" + sample_name + ".bedGraph")),
                    homer_output2=str(Path(sequencing_data["PATH"]) / ("BEDGRAPH/" + sample_name + ".bedGraph.gz")),
                resources:
                    mem_mb=lambda wildcards, attempt: 60000 * attempt,
                    runtime=lambda wildcards, attempt: attempt * 180,
                    qos=lambda wildcards, attempt: get_qos_from_time(attempt, 180),
                shell:
                    r"""
                    bowtie2 -p {threads} --local --very-sensitive-local \
                        --no-mixed --no-discordant --phred33 -I 10 -X 700 \
                        -x "{params.bowtie_ref}" -1 {input[0]} -2 {input[1]} \
                        --rg-id {params.sample} --rg SM:{params.sample} \
                        --rg LB:{params.sequencing} --rg PU:{params.sample}_{params.sequencing} \
                        --rg PL:ILLUMINA -S {params.sam_output} &> {params.bowtie_log}
                    # Check fragment length of mark duplicates
                    samtools view -F 0x04 {params.sam_output} | \
                        awk -F'\t' 'function abs(x){{return ((x < 0.0) ? -x : x)}} {{print abs($9)}}' | \
                        sort | uniq -c | \
                        awk -v OFS="\t" '{{print $2, $1/2}}' > {output[0]}
                    picard SortSam -I {params.sam_output} -O {params.filtered_sam} -SORT_ORDER coordinate
                    picard MarkDuplicates -I {params.filtered_sam} -O {params.filtered2_sam} \
                         -REMOVE_DUPLICATES true \
                         -METRICS_FILE {params.picard_log}
                    # .sam to .bam
                    samtools view -@ {threads} -bS -F 0x04 {params.filtered2_sam} -o {params.bowtie_bam}
                    # add "chr" on the chromosome section and remone non-standard regions
                    samtools view -H {params.bowtie_bam} | \
                        sed -e 's/SN:\([0-9XY]\)/SN:chr\1/' -e 's/SN:MT/SN:chrM/' | \
                        samtools reheader - {params.bowtie_bam} > {output[1]}
                    samtools index {output[1]}
                    samtools view -b {output[1]} chr{{1..22}} chrX chrY > {output[2]}
                    samtools index {output[2]}
                    rm {params.sam_output} {params.filtered_sam} {params.filtered2_sam} {params.bowtie_bam}
                    
                    # HOMER track for UCSC
                    makeTagDirectory {output[3]} {output[2]} -genome {params.genome} -checkGC
                    makeUCSCfile {output[3]} -o {params.homer_output} -norm 1e7
                    gunzip {params.homer_output2}
                    awk '
                    BEGIN {{
                      for (i = 1; i <= 22; i++) chr["chr"i] = 1
                      chr["chrX"] = chr["chrY"] = 1
                    }}
                    NR == 1 {{ print; next }}
                    ($1 in chr) {{ print }}
                    ' {params.homer_output} > {output[4]}
                    
                    # samtools QC
                    samtools flagstat {output[2]} > {output[5]}
                    samtools stats {output[2]} > {output[6]}
                    """
            
            rule:
                name:
                    f"bedtools_{sequencing_name}_{sample_name}"
                input:
                    str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_filtered.bam")),
                output:
                    str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + ".bed")),
                    str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_sorted.bed")),
                    str(Path(sequencing_data["PATH"]) / "BEDGRAPH" / (sample_name + ".bw")),
                threads:
                    config["JOBS"]["CORES_PER_JOBS"]["BEDTOOLS"]
                params:
                    blacklist=config["SEQUENCING"][sequencing_name]["PARAMETERS"]["BLACKLIST_BED"],
                    chromsize=config["SEQUENCING"][sequencing_name]["PARAMETERS"]["CHROM_SIZE"]
                    bed_clean=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_clean.bed")),
                    bed_fragments=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_fragments.bed")),
                    bed_tri=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_tri.bed")),
                    bed_tri2=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_tri2.bed")),
                    bedgraph_norm=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_bowtie2.fragments.normalized.bedGraph")),
                    bedgraph_sort=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_bowtie2.fragments.normalized.bedGraph")),
                resources:
                    mem_mb=lambda wildcards, attempt: 20000 * attempt,
                    runtime=lambda wildcards, attempt: attempt * 180,
                    qos=lambda wildcards, attempt: get_qos_from_time(attempt, 180),
                shell:
                    r"""
                    bedtools bamtobed -i {intput[0]} -bedpe > {output[0]}
                    awk '$1==$4 && $6-$2 < 1000 {{print $0}}' {output[0]} > {params.bed_clean}
                    cut -f 1,2,6 {params.bed_clean} | sort -k1,1 -k2,2n -k3,3n  > {params.bed_fragments}
                    egrep -v 'HG10|HG11|HG12|HG13|PATCH|HSCHR|chrKI|chrHS|chrKB|GL|chrJH|chrM|chrKL|chrAAB|chrMT|NOVEL|KZ|KK|KV|KQ|KB|JH|KI' {params.bed_fragments} > {params.bed_tri}
                    bedtools intersect -a {params.bed_tri} -b {params.blacklist} -f 0.5 -r -v > {params.bed_tri2}
                    bedtools sort -i {params.bed_tri2} > {output[1]}
                    bedtools genomecov -bg -i {output[1]} -g {params.chromsize} > {params.bedgraph_norm}
                    bedtools sort -i {params.bedgrapg_norm} > {params.bedgrapg_sorm}
                    bedGraphToBigWig {params.bedgraph_sorm} {params.chromsize} {output[2]} 
                    rm {params.bed_clean} {params.bed_fragments} {params.bed_tri} {params.bed_tri2} {params.bedgraph_norm} {params.bedgraph_sort}
                    """
        
        if "INPUT" in sequencing_data.keys():        
            for sample_name, sample_data in sequencing_data["INPUT"].items():
                rule:
                    name:
                        f"bowtie2_{sequencing_name}_{sample_name}"
                    input:
                        str(Path(sequencing_data["PATH"]) / sample_data["R1"]),
                        str(Path(sequencing_data["PATH"]) / sample_data["R2"]),
                    output:
                        str(Path(sequencing_data["PATH"]) / "QC/fragmentLen" / (sample_name + "_fragmentLen.txt")),
                        str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_chrheader.bam")),
                        str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_filtered.bam")),
                        directory(str(Path(sequencing_data["PATH"]) / ("HOMER/" + sample_name))),
                        str(Path(sequencing_data["PATH"]) / ("BEDGRAPH/" + sample_name + "_UCSC_track.bedGraph")),
                        str(Path(sequencing_data["PATH"]) / ("QC/flagstat/" + sample_name + "_flagstat.txt")),
                        str(Path(sequencing_data["PATH"]) / ("QC/stats/" + sample_name + "_stats.txt")),
                    threads:
                        config["JOBS"]["CORES_PER_JOBS"]["BOWTIE2"]
                    params:
                        bowtie_ref=sequencing_data["PARAMETERS"]["BOWTIE2_REF"],
                        bowtie_log=str(Path(sequencing_data["PATH"]) / "QC/BOWTIE2/" / (sample_name + ".log")),
                        picard_log=str(Path(sequencing_data["PATH"]) / "QC/PICARD/" / (sample_name + "_picard.rmDup.txt")),
                        sample=sample_name,
                        sequencing=sequencing_name,
                        sam_output=str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + ".sam")),
                        filtered_sam=str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_sorted.sam")),
                        filtered2_sam=str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_rmDup.sam")),
                        bowtie_bam=str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_bowtie.bam")),
                        genome=sequencing_data["PARAMETERS"]["GENOME"],
                        homer_output=str(Path(sequencing_data["PATH"]) / ("BEDGRAPH/" + sample_name + ".bedGraph")),
                        homer_output2=str(Path(sequencing_data["PATH"]) / ("BEDGRAPH/" + sample_name + ".bedGraph.gz")),
                    resources:
                        mem_mb=lambda wildcards, attempt: 60000 * attempt,
                        runtime=lambda wildcards, attempt: attempt * 180,
                        qos=lambda wildcards, attempt: get_qos_from_time(attempt, 180),
                    shell:
                        r"""
                        bowtie2 -p {threads} --local --very-sensitive-local \
                            --no-mixed --no-discordant --phred33 -I 10 -X 700 \
                            -x "{params.bowtie_ref}" -1 {input[0]} -2 {input[1]} \
                            --rg-id {params.sample} --rg SM:{params.sample} \
                            --rg LB:{params.sequencing} --rg PU:{params.sample}_{params.sequencing} \
                            --rg PL:ILLUMINA -S {params.sam_output} &> {params.bowtie_log}
                        # Check fragment length of mark duplicates
                        samtools view -F 0x04 {params.sam_output} | \
                            awk -F'\t' 'function abs(x){{return ((x < 0.0) ? -x : x)}} {{print abs($9)}}' | \
                            sort | uniq -c | \
                            awk -v OFS="\t" '{{print $2, $1/2}}' > {output[0]}
                        picard SortSam -I {params.sam_output} -O {params.filtered_sam} -SORT_ORDER coordinate
                        picard MarkDuplicates -I {params.filtered_sam} -O {params.filtered2_sam} \
                             -REMOVE_DUPLICATES true \
                             -METRICS_FILE {params.picard_log}
                        # .sam to .bam
                        samtools view -@ {threads} -bS -F 0x04 {params.filtered2_sam} -o {params.bowtie_bam}
                        # add "chr" on the chromosome section and remone non-standard regions
                        samtools view -H {params.bowtie_bam} | \
                            sed -e 's/SN:\([0-9XY]\)/SN:chr\1/' -e 's/SN:MT/SN:chrM/' | \
                            samtools reheader - {params.bowtie_bam} > {output[1]}
                        samtools index {output[1]}
                        samtools view -b {output[1]} chr{{1..22}} chrX chrY > {output[2]}
                        samtools index {output[2]}
                        rm {params.sam_output} {params.filtered_sam} {params.filtered2_sam} {params.bowtie_bam}
                        
                        # HOMER track for UCSC
                        makeTagDirectory {output[3]} {output[2]} -genome {params.genome} -checkGC
                        makeUCSCfile {output[3]} -o {params.homer_output} -norm 1e7
                        gunzip {params.homer_output2}
                        awk '
                        BEGIN {{
                          for (i = 1; i <= 22; i++) chr["chr"i] = 1
                          chr["chrX"] = chr["chrY"] = 1
                        }}
                        NR == 1 {{ print; next }}
                        ($1 in chr) {{ print }}
                        ' {params.homer_output} > {output[4]}
                        
                        # samtools QC
                        samtools flagstat {output[2]} > {output[5]}
                        samtools stats {output[2]} > {output[6]}
                        """
                
                rule:
                    name:
                        f"bedtools_{sequencing_name}_{sample_name}"
                    input:
                        str(Path(sequencing_data["PATH"]) / "BAM/" / (sample_name + "_filtered.bam")),
                    output:
                        str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + ".bed")),
                        str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_sorted.bed")),
                        str(Path(sequencing_data["PATH"]) / "BEDGRAPH" / (sample_name + ".bw")),
                    threads:
                        config["JOBS"]["CORES_PER_JOBS"]["BEDTOOLS"]
                    params:
                        blacklist=config["SEQUENCING"][sequencing_name]["PARAMETERS"]["BLACKLIST_BED"],
                        chromsize=config["SEQUENCING"][sequencing_name]["PARAMETERS"]["CHROM_SIZE"]
                        bed_clean=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_clean.bed")),
                        bed_fragments=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_fragments.bed")),
                        bed_tri=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_tri.bed")),
                        bed_tri2=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_tri2.bed")),
                        bedgraph_norm=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_bowtie2.fragments.normalized.bedGraph")),
                        bedgraph_sort=str(Path(sequencing_data["PATH"]) / "BED" / (sample_name + "_bowtie2.fragments.normalized.bedGraph")),
                    resources:
                        mem_mb=lambda wildcards, attempt: 20000 * attempt,
                        runtime=lambda wildcards, attempt: attempt * 180,
                        qos=lambda wildcards, attempt: get_qos_from_time(attempt, 180),
                    shell:
                        r"""
                        bedtools bamtobed -i {intput[0]} -bedpe > {output[0]}
                        awk '$1==$4 && $6-$2 < 1000 {{print $0}}' {output[0]} > {params.bed_clean}
                        cut -f 1,2,6 {params.bed_clean} | sort -k1,1 -k2,2n -k3,3n  > {params.bed_fragments}
                        egrep -v 'HG10|HG11|HG12|HG13|PATCH|HSCHR|chrKI|chrHS|chrKB|GL|chrJH|chrM|chrKL|chrAAB|chrMT|NOVEL|KZ|KK|KV|KQ|KB|JH|KI' {params.bed_fragments} > {params.bed_tri}
                        bedtools intersect -a {params.bed_tri} -b {params.blacklist} -f 0.5 -r -v > {params.bed_tri2}
                        bedtools sort -i {params.bed_tri2} > {output[1]}
                        bedtools genomecov -bg -i {output[1]} -g {params.chromsize} > {params.bedgraph_norm}
                        bedtools sort -i {params.bedgrapg_norm} > {params.bedgrapg_sorm}
                        bedGraphToBigWig {params.bedgraph_sorm} {params.chromsize} {output[2]} 
                        rm {params.bed_clean} {params.bed_fragments} {params.bed_tri} {params.bed_tri2} {params.bedgraph_norm} {params.bedgraph_sort}
                        """
    
    # After alignment
    rule:
        name:
            f"multibamsummary_{sequencing_name}"
        input:
            *chr_paths.get_sequencing_fastq_related_paths(config, sequencing_name, "bam_filtered"),
        output:
            str(Path(sequencing_data["PATH"]) / "QC/CORRELATION" / (sequencing_name + "correlation_matrix.npz")),
            str(Path(sequencing_data["PATH"]) / "QC/CORRELATION" / (sequencing_name + "correlation_plot.png")),
        threads:
            config["JOBS"]["CORES_PER_JOBS"]["MULTIBAMSUMMARY"],
        params:
            labels=lambda wildcards, input: " ".join(Path(b).name.replace("_filtered.bam", "") for b in input)
        resources:
            mem_mb=lambda wildcards, attempt: 10000 * attempt,
            runtime=lambda wildcards, attempt: attempt * 60,
            qos=lambda wildcards, attempt: get_qos_from_time(attempt, 60),
        shell:
            r"""                
            multiBamSummary bins -p {threads} --verbose \
                --bamfiles {input} --labels {params.labels} -o {output[0]}
            
            plotCorrelation -in {output[0]} -c spearman -p heatmap \
                --colorMap RdYlBu -o {output[1]}
            """
    
    
    